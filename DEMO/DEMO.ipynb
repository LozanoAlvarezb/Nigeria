{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prueba de concepto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta notebook expondremos la implementación de un sistema conversacional capaz de contestar preguntas sobre una lista de documentos (adaptado parcialmente de [chat-langchain](https://github.com/hwchase17/chat-langchain)).\n",
    "\n",
    "El proceso se puede separar en los siguientes sistemas:\n",
    "\n",
    "1. _Information Retrieval_ (IR): Para cada pregunta **q** el sistema de IR es el encargado de encontrar el conjunto de documentos **D** donde se encuentra la respuesta.\n",
    "2. _Question Answering_ (QA): El sistema de QA genera la respuesta a la pregunta **q** usando la información presente en el conjunto de documentos **D** . "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Dict, Iterable, List, Optional\n",
    "\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm import tqdm\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "dataset_path = \"data/claims_parse_urls-6m-hard_clean.json\"\n",
    "claims = pd.read_json(\"data/claims_parse_urls-6m-hard_clean.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 18951/18951 [00:00<00:00, 24624.48it/s]\n"
     ]
    }
   ],
   "source": [
    "raw_documents = []\n",
    "for _, claim in tqdm(claims.iterrows(),total=len(claims)):\n",
    "    text = claim[\"text\"]\n",
    "    metadata = {\n",
    "        \"id\": claim[\"_id\"],\n",
    "        \"claimReviewed\": claim[\"claimReviewed\"],\n",
    "        \"url\": claim[\"url\"],\n",
    "    }\n",
    "    raw_documents.append({\"text\":text,\"metadata\":metadata})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera **decisión de diseño** consiste en como crear los documentos que servirán como fuentes para el sistema de QA. \n",
    "\n",
    "En este caso se ha optado por dividir cada artículo en segmentos de tamaño menor o igual a _chunk_size_ caractéres (1000) con una ventana deslizante de, como máximo, _chunk_overlap_ caracteres (200).\n",
    "\n",
    "Para que los segmentos sean semanticamente coherentes y sintacticamente correctos se divide recursivamente el texto usando distintos separadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000\n",
    "chunk_overlap = 200\n",
    "\n",
    "separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_docs(docs: List[str], separator: str) -> Optional[str]:\n",
    "    text = separator.join(docs)\n",
    "    text = text.strip()\n",
    "    if text == \"\":\n",
    "        return None\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "def merge_splits(splits: Iterable[str], separator: str) -> List[str]:\n",
    "    # We now want to combine these smaller pieces into medium size\n",
    "    # chunks to send to the LLM.\n",
    "    separator_len = len(separator)\n",
    "\n",
    "    docs = []\n",
    "    current_doc: List[str] = []\n",
    "    total = 0\n",
    "    for d in splits:\n",
    "        _len = len(d)\n",
    "        if (\n",
    "            total + _len + (separator_len if len(current_doc) > 0 else 0)\n",
    "            > chunk_size\n",
    "        ):\n",
    "            if total > chunk_size:\n",
    "                print(\n",
    "                    f\"Created a chunk of size {total}, \"\n",
    "                    f\"which is longer than the specified {chunk_size}\"\n",
    "                )\n",
    "            if len(current_doc) > 0:\n",
    "                doc = join_docs(current_doc, separator)\n",
    "                if doc is not None:\n",
    "                    docs.append(doc)\n",
    "                # Keep on popping if:\n",
    "                # - we have a larger chunk than in the chunk overlap\n",
    "                # - or if we still have any chunks and the length is long\n",
    "                while total > chunk_overlap or (\n",
    "                    total + _len + (separator_len if len(current_doc) > 0 else 0)\n",
    "                    > chunk_size\n",
    "                    and total > 0\n",
    "                ):\n",
    "                    total -= len(current_doc[0]) + (\n",
    "                        separator_len if len(current_doc) > 1 else 0\n",
    "                    )\n",
    "                    current_doc = current_doc[1:]\n",
    "        current_doc.append(d)\n",
    "        total += _len + (separator_len if len(current_doc) > 1 else 0)\n",
    "    doc = join_docs(current_doc, separator)\n",
    "    if doc is not None:\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "\n",
    "def split_text(text: str) -> List[str]:\n",
    "    \"\"\"Split incoming text and return chunks.\"\"\"\n",
    "    final_chunks = []\n",
    "    # Get appropriate separator to use\n",
    "    for _s in separators:\n",
    "        if _s == \"\":\n",
    "            separator = _s\n",
    "            break\n",
    "        if _s in text:\n",
    "            separator = _s\n",
    "            break\n",
    "    # Now that we have the separator, split the text\n",
    "    if separator:\n",
    "        splits = text.split(separator)\n",
    "    else:\n",
    "        splits = list(text)\n",
    "    # Now go merging things, recursively splitting longer texts.\n",
    "    _good_splits = []\n",
    "    for s in splits:\n",
    "        if len(s) < chunk_size:\n",
    "            _good_splits.append(s)\n",
    "        else:\n",
    "            if _good_splits:\n",
    "                merged_text = merge_splits(_good_splits, separator)\n",
    "                final_chunks.extend(merged_text)\n",
    "                _good_splits = []\n",
    "            other_info = split_text(s)\n",
    "            final_chunks.extend(other_info)\n",
    "    if _good_splits:\n",
    "        merged_text = merge_splits(_good_splits, separator)\n",
    "        final_chunks.extend(merged_text)\n",
    "    return final_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 18951/18951 [00:00<00:00, 42260.75it/s]\n"
     ]
    }
   ],
   "source": [
    "documents = []\n",
    "for document in tqdm(raw_documents):\n",
    "    text = document[\"text\"]\n",
    "    metadata = document[\"metadata\"]\n",
    "\n",
    "    splits = split_text(text)\n",
    "    for chunk in splits:\n",
    "        new_doc = {\"text\":chunk,\"metadata\":metadata}\n",
    "        documents.append(new_doc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sistema de IR es el encargado de recupererar el conjunto de documentos donde se encuentra la respuesta. \n",
    "\n",
    "Todos los documentos y la query se representan usando vectores densos, obtenidos mediante un modelo _SentenceTransformer_. La relevancia que tiene un documento $d$ para la query $q$ viene dada por el producto escalar entre ambos, $d\\cdot q$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"paraphrase-multilingual-MiniLM-L12-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235d5d0ff2a541b1b6183b8a25dbff47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3030 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorstore = model.encode([doc[\"text\"] for doc in documents],show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/vectorstore.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorstore, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Si ya has codificado los documentos puedes cargar el indice ejecutando la siguiente celda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/vectorstore.pkl\", \"rb\") as f:\n",
    "    vectorstore = pickle.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Index:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        documents: List[Dict[str,Any]],\n",
    "        vectorstore: np.ndarray,\n",
    "        model: SentenceTransformer\n",
    "    ):\n",
    "        self.documents = documents\n",
    "        self.vectorstore = vectorstore\n",
    "        self.model = model\n",
    "    \n",
    "    def search(\n",
    "        self,\n",
    "        query: str,\n",
    "        k: int=4\n",
    "    ):\n",
    "        \"\"\"Retrieves the top k documents from the index, by relevance to the query\"\"\"\n",
    "        query_embedding = self.model.encode(query)\n",
    "        scores = util.dot_score(query_embedding, self.vectorstore)\n",
    "        scores = scores.squeeze()\n",
    "\n",
    "        # Bigger is better\n",
    "        topk = (-scores).argsort()[:k]\n",
    "\n",
    "        return [{**self.documents[i],\"score\":scores[i].item() } for i in topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Index(documents,vectorstore,model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLM:\n",
    "    \n",
    "    @abstractmethod\n",
    "    def completition(self):\n",
    "        \"\"\"Generate text\"\"\"\n",
    "\n",
    "class GPT(LLM):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str = \"text-davinci-003\",\n",
    "        temperature= 0.0,\n",
    "        max_tokens=256,\n",
    "        top_p= 1,\n",
    "        frequency_penalty = 0,\n",
    "        presence_penalty= 0,\n",
    "        n= 1,\n",
    "        logit_bias= {}\n",
    "    ):\n",
    "        self.params = {\n",
    "            \"model\":model, \n",
    "            \"temperature\":temperature, \n",
    "            \"max_tokens\":max_tokens, \n",
    "            \"top_p\":top_p, \n",
    "            \"frequency_penalty\":frequency_penalty, \n",
    "            \"presence_penalty\":presence_penalty, \n",
    "            \"n\":n, \n",
    "            \"logit_bias\":logit_bias,    \n",
    "        }\n",
    "\n",
    "    def completion(\n",
    "        self,\n",
    "        prompt\n",
    "    ):\n",
    "        response = openai.Completion.create(\n",
    "            prompt=prompt,\n",
    "            **self.params\n",
    "        )\n",
    "        return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = GPT()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_separator = '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "history_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatQA:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ir,\n",
    "        qa\n",
    "    ):\n",
    "        self.ir = ir\n",
    "        self.qa = qa\n",
    "\n",
    "        self.history = []\n",
    "\n",
    "    def reset(self):\n",
    "        self.history = []\n",
    "        \n",
    "    def follow_up_query(self,question):\n",
    "        prompt = history_template.format(chat_history=\"/n\".join(self.history),question=question)\n",
    "        query = self.qa.completion(prompt)\n",
    "        print(query)\n",
    "        return query\n",
    "\n",
    "    def __call__(\n",
    "        self,\n",
    "        question:str\n",
    "    ):\n",
    "        if len(self.history):\n",
    "            query = self.follow_up_query(question)\n",
    "        else:\n",
    "            query = question\n",
    "\n",
    "        documents = self.ir.search(query)\n",
    "\n",
    "        contexts = [document[\"text\"] for document in documents]\n",
    "        context = document_separator.join(contexts)\n",
    "        prompt =  question_template.format(context=context,question=query)\n",
    "\n",
    "        answer = self.qa.completion(prompt)\n",
    "\n",
    "        self.history.append(\"\\n\".join([prompt,answer]))\n",
    "\n",
    "        urls = [document[\"metadata\"][\"url\"] for document in documents]\n",
    "        urls = list(dict.fromkeys(urls))\n",
    "        citation = [f'{i+1}. {url}' for i,url in enumerate(urls)]\n",
    "\n",
    "        return \"\\n\".join([answer,*citation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatQA(index,llm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Reaccionó Piqué al tema de Shakira diciendo que \"esto lo he aguantado durante 15 años\"?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, ese no es el contenido del vídeo original. El vídeo original no tiene relación con la cantante y el audio que se reproduce es de un excompañero de equipo de Piqué.\n",
      "1. https://www.newtral.es/comunicado-casio-shakira-pique-bulo/20230118/\n",
      "2. https://observador.pt/factchecks/fact-check-casio-comparou-bateria-dos-seus-relogios-a-relacao-de-shakira-e-pique/\n",
      "3. https://maldita.es/malditobulo/20230116/pique-reacciona-directo-shakira/\n"
     ]
    }
   ],
   "source": [
    "print(chat(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'Es cierto que el zumo de limón en ayunas adelgaza?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No hay suficiente evidencia científica para respaldar esta afirmación.\n",
      "1. https://fullfact.org/health/lemons-and-cancer/\n",
      "2. https://www.thip.media/health-news-fact-check/fact-check-can-lemon-and-baking-soda-act-as-an-effective-teeth-whitener/36654/\n",
      "3. https://newschecker.in/fact-check/ganesh-chaturthi-overseas/\n"
     ]
    }
   ],
   "source": [
    "print(chat(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El ataque a Nicolás Maduro no ocurrió en el 2022, sino en el 2017. Fue durante la conmemoración de los 200 años de la Batalla de San Félix.\n",
      "1. https://colombiacheck.com/chequeos/estados-unidos-no-ha-anunciado-que-maduro-ha-sido-declarado-objetivo-en-enero-de-2023\n",
      "2. https://www.newtral.es/ataque-nicolas-maduro-venezuela/20220830/\n"
     ]
    }
   ],
   "source": [
    "question = 'Porque fue Nicolás Maduro atacado por un grupo de personas en San Felix (Venezuela) en el 2022?'\n",
    "print(chat(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No sé.\n",
      "1. https://www.newtral.es/votos-socios-investidura-jaume-asens-factcheck/20221104/\n",
      "2. https://www.polygraph.info/a/fact-check-before-ouster-peru-castillo-misled-about-closing-congress/6869620.html\n",
      "3. https://www.newtral.es/pedro-sanchez-candidato-partido-socialista-europeo-internacional/20221026/\n",
      "4. https://colombiacheck.com/chequeos/venezolano-no-cometio-el-primer-atraco-en-islandia-se-trata-de-una-noticia-falsa-de-una\n"
     ]
    }
   ],
   "source": [
    "question = 'Cual es el político español que más cobra?'\n",
    "print(chat(question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No, he did not say that.\n",
      "1. https://www.newtral.es/comunicado-casio-shakira-pique-bulo/20230118/\n",
      "2. https://observador.pt/factchecks/fact-check-casio-comparou-bateria-dos-seus-relogios-a-relacao-de-shakira-e-pique/\n",
      "3. https://www.verificat.cat/fact-check/pique-no-va-posar-la-canco-de-shakira-i-bizarrap-en-un-directe-de-la-kings-league-ni-va-arribar-a-lestadi-escoltant-la-son-muntatges\n"
     ]
    }
   ],
   "source": [
    "question = 'Did Piqué react to the Shakira issue by saying that \"I\\'ve put up with this for 15 years\"?'\n",
    "print(chat(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Is it true that drinking lemon juice on an empty stomach can help with weight loss?\n",
      " No, that's not true. A clinical dietician told Lead Stories that drinking lemon juice on an empty stomach is not recommended and poses a danger to a person's health. A medical doctor specializing in weight loss confirmed this, telling Lead Stories that this juice mix won't cause significant weight loss and that weight loss is best achieved through healthy diet, exercise and maintaining healthy body weight.\n",
      "1. https://fullfact.org/health/lemons-and-cancer/\n",
      "2. https://leadstories.com/hoax-alert/2022/10/fact-check-these-fruits-will-not-cause-you-to-lose-15-pounds-in-21-days.html\n",
      "3. https://leadstories.com/hoax-alert/2022/08/fact-check-losing-20-pounds-in-20-days-and-preventing-diabetes-with-this-juice-is-not-practical.html\n"
     ]
    }
   ],
   "source": [
    "question = 'Is it true that lemon juice on an empty stomach is slimming?'\n",
    "print(chat(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " What was the reason for the attack on Nicolás Maduro in San Felix, Venezuela in 2022?\n",
      " The attack on Nicolás Maduro in San Felix, Venezuela in 2017 was to commemorate the 200th anniversary of the Battle of San Felix.\n",
      "1. https://colombiacheck.com/chequeos/estados-unidos-no-ha-anunciado-que-maduro-ha-sido-declarado-objetivo-en-enero-de-2023\n",
      "2. https://www.newtral.es/ataque-nicolas-maduro-venezuela/20220830/\n",
      "3. https://colombiacheck.com/chequeos/es-falso-que-petro-haya-advertido-que-invadiria-venezuela-tras-ataque-militares\n"
     ]
    }
   ],
   "source": [
    "question = 'Why was Nicolás Maduro attacked by a group of people in San Felix (Venezuela) in 2022?'\n",
    "print(chat(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Who is the highest paid Spanish politician?\n",
      " No sé.\n",
      "1. https://www.newtral.es/votos-socios-investidura-jaume-asens-factcheck/20221104/\n",
      "2. https://malayalam.indiatoday.in/fact-check/story/fact-check-sonia-gandhi-indeed-worlds-fourth-richest-politician-452005-2022-09-27\n",
      "3. https://factual.afp.com/doc.afp.com.337C3GQ\n",
      "4. https://www.newtral.es/presion-fiscal-pp-sanchez-antonio-sanz-factcheck/20220928/\n"
     ]
    }
   ],
   "source": [
    "question = 'Who is the highest paid Spanish politician?'\n",
    "print(chat(question))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def reset_chat():\n",
    "    chat.reset()\n",
    "    return ''\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot()\n",
    "    chat = ChatQA(index,llm)\n",
    "    msg = gr.Textbox(placeholder=\"Enter text and press enter, or upload an image\",)\n",
    "    clear = gr.Button(\"Clear\")\n",
    "\n",
    "    def respond(question, chat_history):\n",
    "        bot_message = chat(question)\n",
    "        chat_history.append((question, bot_message))\n",
    "        return \"\", chat_history\n",
    "\n",
    "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "    clear.click(reset_chat, None, chatbot, queue=False)\n",
    "\n",
    "demo.launch();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
